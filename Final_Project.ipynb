{"nbformat":4,"nbformat_minor":0,"metadata":{"colab":{"name":"Final_Project.ipynb","provenance":[{"file_id":"1tyd-zioA-LqaAUaG2vu9p_K9RX78qnW_","timestamp":1600234130356},{"file_id":"18PS4L2wHV3vgMWkBX5uPQQtzfN8jgoWu","timestamp":1599259311739}],"collapsed_sections":[]},"kernelspec":{"name":"python3","display_name":"Python 3"},"widgets":{"application/vnd.jupyter.widget-state+json":{"50f724af23f04af2b5e739c779a9414d":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_27552bf64b294517bf53f7d9f7430aa8","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_2b997c7a13e34b7c91e5ffde2802b7b1","IPY_MODEL_7a281dd1d4564a55aa74fe206b2c6e9a"]}},"27552bf64b294517bf53f7d9f7430aa8":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"2b997c7a13e34b7c91e5ffde2802b7b1":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_b44e8a9a09604b67ad76ff4091e23e7c","_dom_classes":[],"description":"Epoch: 50: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_9abaf2e915864851bb035bf968ae7a0e"}},"7a281dd1d4564a55aa74fe206b2c6e9a":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_19fed366f3444c87a1801bec1a13289d","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [26:47&lt;00:00, 32.16s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_73b9b864a744452ba91580c775567ad4"}},"b44e8a9a09604b67ad76ff4091e23e7c":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"9abaf2e915864851bb035bf968ae7a0e":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"19fed366f3444c87a1801bec1a13289d":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"73b9b864a744452ba91580c775567ad4":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"32f9eb33991b41649df4200b8cae5070":{"model_module":"@jupyter-widgets/controls","model_name":"HBoxModel","state":{"_view_name":"HBoxView","_dom_classes":[],"_model_name":"HBoxModel","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.5.0","box_style":"","layout":"IPY_MODEL_ad1ac88c2b8f4f41b4c379168839f61d","_model_module":"@jupyter-widgets/controls","children":["IPY_MODEL_92ee07c9e78d47cea915990a73c72d71","IPY_MODEL_16340b3e2a764961b7b1e9d29de18ea8"]}},"ad1ac88c2b8f4f41b4c379168839f61d":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"92ee07c9e78d47cea915990a73c72d71":{"model_module":"@jupyter-widgets/controls","model_name":"FloatProgressModel","state":{"_view_name":"ProgressView","style":"IPY_MODEL_6687f0b579ff4ff9b15c527795066de1","_dom_classes":[],"description":"Epoch: 50: 100%","_model_name":"FloatProgressModel","bar_style":"success","max":50,"_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":50,"_view_count":null,"_view_module_version":"1.5.0","orientation":"horizontal","min":0,"description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_652599fcd79040c382b29f1721851607"}},"16340b3e2a764961b7b1e9d29de18ea8":{"model_module":"@jupyter-widgets/controls","model_name":"HTMLModel","state":{"_view_name":"HTMLView","style":"IPY_MODEL_f0bc6664e62243a8bef99229109e9245","_dom_classes":[],"description":"","_model_name":"HTMLModel","placeholder":"​","_view_module":"@jupyter-widgets/controls","_model_module_version":"1.5.0","value":" 50/50 [05:12&lt;00:00,  6.26s/it]","_view_count":null,"_view_module_version":"1.5.0","description_tooltip":null,"_model_module":"@jupyter-widgets/controls","layout":"IPY_MODEL_47e77901e4554a078bfcda1a4fcec0af"}},"6687f0b579ff4ff9b15c527795066de1":{"model_module":"@jupyter-widgets/controls","model_name":"ProgressStyleModel","state":{"_view_name":"StyleView","_model_name":"ProgressStyleModel","description_width":"initial","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","bar_color":null,"_model_module":"@jupyter-widgets/controls"}},"652599fcd79040c382b29f1721851607":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}},"f0bc6664e62243a8bef99229109e9245":{"model_module":"@jupyter-widgets/controls","model_name":"DescriptionStyleModel","state":{"_view_name":"StyleView","_model_name":"DescriptionStyleModel","description_width":"","_view_module":"@jupyter-widgets/base","_model_module_version":"1.5.0","_view_count":null,"_view_module_version":"1.2.0","_model_module":"@jupyter-widgets/controls"}},"47e77901e4554a078bfcda1a4fcec0af":{"model_module":"@jupyter-widgets/base","model_name":"LayoutModel","state":{"_view_name":"LayoutView","grid_template_rows":null,"right":null,"justify_content":null,"_view_module":"@jupyter-widgets/base","overflow":null,"_model_module_version":"1.2.0","_view_count":null,"flex_flow":null,"width":null,"min_width":null,"border":null,"align_items":null,"bottom":null,"_model_module":"@jupyter-widgets/base","top":null,"grid_column":null,"overflow_y":null,"overflow_x":null,"grid_auto_flow":null,"grid_area":null,"grid_template_columns":null,"flex":null,"_model_name":"LayoutModel","justify_items":null,"grid_row":null,"max_height":null,"align_content":null,"visibility":null,"align_self":null,"height":null,"min_height":null,"padding":null,"grid_auto_rows":null,"grid_gap":null,"max_width":null,"order":null,"_view_module_version":"1.2.0","grid_template_areas":null,"object_position":null,"object_fit":null,"grid_auto_columns":null,"margin":null,"display":null,"left":null}}}},"accelerator":"GPU"},"cells":[{"cell_type":"markdown","metadata":{"id":"L6J7qxGBRjd2","colab_type":"text"},"source":["## Models and Functions ##"]},{"cell_type":"code","metadata":{"id":"lF3wXGeruJp2","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600388858008,"user_tz":420,"elapsed":4095,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}}},"source":["# Import Libraries\n","import csv\n","import re\n","import os\n","import string\n","from tqdm.notebook import tqdm\n","\n","import torch\n","import torch.nn as nn\n","import torch.optim as optim\n","import torch.nn.functional as F"],"execution_count":2,"outputs":[]},{"cell_type":"code","metadata":{"id":"WfK01NNpUuGL","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":510},"executionInfo":{"status":"ok","timestamp":1600388858922,"user_tz":420,"elapsed":3184,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"0f7f88a9-abed-496f-8a45-a268634d749c"},"source":["# Download File\n","if not os.path.exists(\"semeval-2020-task-7-dataset\"):\n","  !wget https://cs.rochester.edu/u/nhossain/semeval-2020-task-7-dataset.zip\n","  !unzip semeval-2020-task-7-dataset.zip"],"execution_count":3,"outputs":[{"output_type":"stream","text":["--2020-09-18 00:27:37--  https://cs.rochester.edu/u/nhossain/semeval-2020-task-7-dataset.zip\n","Resolving cs.rochester.edu (cs.rochester.edu)... 192.5.53.208\n","Connecting to cs.rochester.edu (cs.rochester.edu)|192.5.53.208|:443... connected.\n","HTTP request sent, awaiting response... 200 OK\n","Length: 1621456 (1.5M) [application/zip]\n","Saving to: ‘semeval-2020-task-7-dataset.zip’\n","\n","semeval-2020-task-7 100%[===================>]   1.55M  3.62MB/s    in 0.4s    \n","\n","2020-09-18 00:27:38 (3.62 MB/s) - ‘semeval-2020-task-7-dataset.zip’ saved [1621456/1621456]\n","\n","Archive:  semeval-2020-task-7-dataset.zip\n","   creating: semeval-2020-task-7-dataset/\n","  inflating: semeval-2020-task-7-dataset/.DS_Store  \n","   creating: semeval-2020-task-7-dataset/subtask-1/\n","  inflating: semeval-2020-task-7-dataset/subtask-1/train_funlines.csv  \n","  inflating: semeval-2020-task-7-dataset/subtask-1/.DS_Store  \n","  inflating: semeval-2020-task-7-dataset/subtask-1/test.csv  \n","  inflating: semeval-2020-task-7-dataset/subtask-1/dev.csv  \n"," extracting: semeval-2020-task-7-dataset/subtask-1/baseline.zip  \n","  inflating: semeval-2020-task-7-dataset/subtask-1/train.csv  \n","  inflating: semeval-2020-task-7-dataset/README.txt  \n","   creating: semeval-2020-task-7-dataset/subtask-2/\n","  inflating: semeval-2020-task-7-dataset/subtask-2/train_funlines.csv  \n","  inflating: semeval-2020-task-7-dataset/subtask-2/.DS_Store  \n","  inflating: semeval-2020-task-7-dataset/subtask-2/test.csv  \n","  inflating: semeval-2020-task-7-dataset/subtask-2/dev.csv  \n"," extracting: semeval-2020-task-7-dataset/subtask-2/baseline.zip  \n","  inflating: semeval-2020-task-7-dataset/subtask-2/train.csv  \n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"h_JO7IqMB9FZ","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600388862116,"user_tz":420,"elapsed":644,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}}},"source":["# Utility Functions\n","\n","# Preprocess function\n","def get_tokenized_corpus(corpus):\n","  punctuation = string.punctuation.replace('*', '')\n","  tokenized_corpus = []\n","  \n","  for sentence in corpus:\n","    sentence = \"\".join([i for i in sentence if i not in punctuation]) # Punctuation removal\n","    sentence = sentence.lower() # convert to lowercase\n","    tokenized_sentence = []\n","    for token in sentence.split(' '): \n","      tokenized_sentence.append(token)\n","    tokenized_corpus.append(tokenized_sentence)\n","  return tokenized_corpus\n","\n","def get_word2idx(tokenized_corpus):\n","  vocabulary = []\n","  for sentence in tokenized_corpus:\n","    for token in sentence:\n","        if token not in vocabulary:\n","            vocabulary.append(token)\n","  \n","  word2idx = {w: idx+1 for (idx, w) in enumerate(vocabulary)}\n","  # we reserve the 0 index for the padding token\n","  word2idx['<pad>'] = 0\n"," \n","  return word2idx\n","\n","def get_model_inputs(tokenized_corpus, word2idx, labels):\n","  # we index our sentences\n","  vectorized_sents = [[word2idx[tok] for tok in sent if tok in word2idx] for sent in tokenized_corpus]\n","\n","  # Sentence lengths\n","  sent_lengths = [len(sent) for sent in vectorized_sents]\n","\n","  # Get maximum length\n","  max_len = max(sent_lengths)\n","  \n","  # we create a tensor of a fixed size filled with zeroes for padding\n","  sent_tensor = torch.zeros((len(vectorized_sents), max_len)).long()\n","\n","  # we fill it with our vectorized sentences \n","  for idx, (sent, sentlen) in enumerate(zip(vectorized_sents, sent_lengths)):\n","    sent_tensor[idx, :sentlen] = torch.LongTensor(sent)\n","\n","  # Label tensor\n","  label_tensor = torch.FloatTensor(labels)\n","  \n","  return sent_tensor, label_tensor\n","\n","# Define the test input function\n","def get_test_inputs(tokenized_corpus, word2idx):\n","  # we index our sentences\n","  vectorized_sents = [[word2idx[tok] for tok in sent if tok in word2idx] for sent in tokenized_corpus]\n","\n","  # Sentence lengths\n","  sent_lengths = [len(sent) for sent in vectorized_sents]\n","\n","  # Get maximum length\n","  max_len = max(sent_lengths)\n","  \n","  # we create a tensor of a fixed size filled with zeroes for padding\n","  sent_tensor = torch.zeros((len(vectorized_sents), max_len)).long()\n","\n","  # we fill it with our vectorized sentences \n","  for idx, (sent, sentlen) in enumerate(zip(vectorized_sents, sent_lengths)):\n","    sent_tensor[idx, :sentlen] = torch.LongTensor(sent)\n","\n","  return sent_tensor"],"execution_count":4,"outputs":[]},{"cell_type":"code","metadata":{"id":"EgnJPHO_ReoO","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600388866197,"user_tz":420,"elapsed":562,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}}},"source":["# RNN model\n","class RNN(nn.Module):\n","\n","    def __init__(self, vocab_size, embedding_dim, hidden_dim, output_dim,\n","                 bidirectional, dropout, pad_idx, variant):\n","\n","        super().__init__()\n","\n","        self.variant = variant\n","        self.bidirectional = bidirectional\n","        self.hidden_dim = hidden_dim\n","\n","        # Embedding layer\n","        self.embedding = nn.Embedding(vocab_size, embedding_dim, padding_idx=pad_idx)\n","        \n","        # One single unidirectional RNN, bidirectional RNN or LSTM layer.\n","        if self.variant == 'rnn':\n","          self.rnn = nn.RNN(embedding_dim,\n","                            hidden_dim,\n","                            batch_first=True,\n","                            bidirectional=bidirectional,\n","                            num_layers=1)\n","        elif self.variant == 'lstm':\n","          self.rnn = nn.LSTM(embedding_dim, \n","                               hidden_dim, \n","                               batch_first=True)\n","          \n","        if self.bidirectional and self.variant != 'lstm':\n","            linear_hidden_in = hidden_dim * 2\n","        else:\n","            linear_hidden_in = hidden_dim\n","            \n","\n","        # The output (linear) layer\n","        self.fc = nn.Linear(linear_hidden_in, output_dim)\n","        \n","        # Dropout\n","        self.dropout = nn.Dropout(dropout)\n","    \n","    def forward(self, text):\n","\n","        # Apply dropout to the embedding layer\n","        embedded = self.dropout(self.embedding(text))\n","        # Store the returned values from the RNN layer\n","        all_hidden, last_hidden = self.rnn(embedded)\n","\n","        if self.variant == \"lstm\":\n","          last_hidden = last_hidden[0]\n","        elif self.bidirectional:\n","            # Concat the final forward (hidden[0,:,:]) and backward (hidden[1,:,:]) hidden layers\n","            last_hidden = torch.cat((last_hidden[0, :, :], last_hidden[1, :, :]), dim=-1)\n","        else:\n","          last_hidden = last_hidden.squeeze(0)\n","\n","        # Output redictions.\n","        logits = self.fc(self.dropout(last_hidden))\n","        \n","        return logits"],"execution_count":5,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"X2PEkD2YBrKb","colab_type":"text"},"source":["## Subtask 1 ##"]},{"cell_type":"code","metadata":{"id":"7SSS-3YxuNdx","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600388869674,"user_tz":420,"elapsed":588,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"e9b7cf34-d873-40b1-869b-fb3c5f32c755"},"source":["# Download File\n","if not os.path.exists(\"semeval-2020-task-7-dataset\"):\n","  !wget https://cs.rochester.edu/u/nhossain/semeval-2020-task-7-dataset.zip\n","  !unzip semeval-2020-task-7-dataset.zip\n","\n","id = set()\n","corpus = []\n","grade = []\n","\n","with open('semeval-2020-task-7-dataset/subtask-1/train.csv', newline='') as csvfile:\n","  reader = csv.DictReader(csvfile)\n","  for row in reader:\n","    if not row['id'] in id:\n","      edit = row['edit']\n","      corpus.append(re.sub('<[a-zA-z0-9]*/>', edit, row['original'])) # Substitute original tag with edits\n","      grade.append(float(row['meanGrade']))\n","      id.add(row['id'])\n","\n","with open('semeval-2020-task-7-dataset/subtask-1/train_funlines.csv', newline='') as csvfile:\n","  reader = csv.DictReader(csvfile)\n","  for row in reader:\n","    if not row['id'] in id:   \n","      edit = row['edit']\n","      corpus.append(re.sub('<[a-zA-z0-9]*/>', edit, row['original'])) # Substitute original tag with edits\n","      grade.append(float(row['meanGrade']))\n","      id.add(row['id'])\n","\n","print(\"Result: \")\n","print(\"Corpus size: \" + str(len(corpus)))"],"execution_count":6,"outputs":[{"output_type":"stream","text":["Result: \n","Corpus size: 17900\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"UQ7YOT-juPP1","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1600388880807,"user_tz":420,"elapsed":8125,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"60a2b543-3394-4909-ec26-060acf21a0fb"},"source":["# Preprocess Corpus\n","tokenized_corpus = get_tokenized_corpus(corpus)\n","print(len(tokenized_corpus))\n","word2idx = get_word2idx(tokenized_corpus)\n","train_sent_tensor, train_label_tensor = get_model_inputs(tokenized_corpus, word2idx, grade)\n","\n","print(f'Vocabulary size: {len(word2idx)}')\n","print('Training set tensor:')\n","print(train_sent_tensor.size())\n","print(train_sent_tensor[0])\n","print('Training Label tensor:')\n","print(train_label_tensor.size())"],"execution_count":7,"outputs":[{"output_type":"stream","text":["17900\n","Vocabulary size: 17103\n","Training set tensor:\n","torch.Size([17900, 28])\n","tensor([ 1,  2,  3,  4,  5,  6,  7,  8,  9, 10, 11, 12, 13, 14, 15,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n","Training Label tensor:\n","torch.Size([17900])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"0D6f6hZYkEwm","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600389815540,"user_tz":420,"elapsed":393,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}}},"source":["# Hyperparameters\n","INPUT_DIM = len(word2idx)\n","EMBEDDING_DIM = 100\n","HIDDEN_DIM = 300\n","OUTPUT_DIM = 1\n","BIDIRECTIONAL = False\n","DROPOUT = 0.3\n","PAD_IDX = 0\n","EPOCHS = 50\n","\n","model = RNN(INPUT_DIM, \n","            EMBEDDING_DIM, \n","            HIDDEN_DIM, \n","            OUTPUT_DIM, \n","            BIDIRECTIONAL, \n","            DROPOUT, \n","            PAD_IDX,\n","            'lstm')"],"execution_count":10,"outputs":[]},{"cell_type":"code","metadata":{"id":"QqdsOtzYuTMg","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["50f724af23f04af2b5e739c779a9414d","27552bf64b294517bf53f7d9f7430aa8","2b997c7a13e34b7c91e5ffde2802b7b1","7a281dd1d4564a55aa74fe206b2c6e9a","b44e8a9a09604b67ad76ff4091e23e7c","9abaf2e915864851bb035bf968ae7a0e","19fed366f3444c87a1801bec1a13289d","73b9b864a744452ba91580c775567ad4"]},"executionInfo":{"status":"ok","timestamp":1600391426648,"user_tz":420,"elapsed":1608547,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"e9d73ca4-4c9e-4a81-afc8-38c9f6ad9683"},"source":["# Print the model\n","print(model)\n","\n","# we use the stochastic gradient descent (SGD) optimizer\n","# optimizer = optim.SGD(model.parameters(), lr=LRATE)\n","optimizer = optim.Adam(model.parameters())\n","\n","# Use RMSE for loss\n","eps = 1e-6\n","MSE = nn.MSELoss()\n","loss_fn = lambda predictions, target : torch.sqrt(MSE(predictions, target) + eps) #RMSE\n","#loss_fn = nn.MSELoss()\n","\n","# Input and label tensors\n","feature = train_sent_tensor\n","target = train_label_tensor\n","\n","################\n","# Start training\n","################\n","print(f'Will train for {EPOCHS} epochs')\n","loss_hist = []\n","\n","with tqdm(range(1, EPOCHS + 1)) as pbar:\n","  for epoch in pbar:\n","    # to ensure the dropout (explained later) is \"turned on\" while training\n","    # good practice to include even if do not use here\n","    model.train()\n","    \n","    # we zero the gradients as they are not removed automatically\n","    optimizer.zero_grad()\n","    \n","    # squeeze is needed as the predictions will have the shape (batch size, 1)\n","    # and we need to remove the dimension of size 1\n","    predictions = model(feature).squeeze()\n","\n","    # Compute the loss\n","    loss = loss_fn(predictions, target)\n","    # Q. Compute here the MSE loss\n","    train_loss = loss.item()\n","\n","    # calculate the gradient of each parameter\n","    loss.backward()\n","\n","    # update the parameters using the gradients and optimizer algorithm \n","    optimizer.step()\n","    \n","    pbar.set_description(f'Epoch: {epoch:02}')\n","    print(f'Epoch: {epoch:02}, Train Loss: {train_loss:.3f}')\n","    loss_hist.append(train_loss)\n"],"execution_count":11,"outputs":[{"output_type":"stream","text":["RNN(\n","  (embedding): Embedding(17103, 100, padding_idx=0)\n","  (rnn): LSTM(100, 300, batch_first=True)\n","  (fc): Linear(in_features=300, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.3, inplace=False)\n",")\n","Will train for 50 epochs\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"50f724af23f04af2b5e739c779a9414d","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch: 01, Train Loss: 1.231\n","Epoch: 02, Train Loss: 1.190\n","Epoch: 03, Train Loss: 1.147\n","Epoch: 04, Train Loss: 1.100\n","Epoch: 05, Train Loss: 1.043\n","Epoch: 06, Train Loss: 0.963\n","Epoch: 07, Train Loss: 0.829\n","Epoch: 08, Train Loss: 0.670\n","Epoch: 09, Train Loss: 0.710\n","Epoch: 10, Train Loss: 0.628\n","Epoch: 11, Train Loss: 0.660\n","Epoch: 12, Train Loss: 0.659\n","Epoch: 13, Train Loss: 0.632\n","Epoch: 14, Train Loss: 0.602\n","Epoch: 15, Train Loss: 0.607\n","Epoch: 16, Train Loss: 0.631\n","Epoch: 17, Train Loss: 0.617\n","Epoch: 18, Train Loss: 0.599\n","Epoch: 19, Train Loss: 0.603\n","Epoch: 20, Train Loss: 0.610\n","Epoch: 21, Train Loss: 0.614\n","Epoch: 22, Train Loss: 0.612\n","Epoch: 23, Train Loss: 0.606\n","Epoch: 24, Train Loss: 0.600\n","Epoch: 25, Train Loss: 0.600\n","Epoch: 26, Train Loss: 0.604\n","Epoch: 27, Train Loss: 0.607\n","Epoch: 28, Train Loss: 0.605\n","Epoch: 29, Train Loss: 0.600\n","Epoch: 30, Train Loss: 0.598\n","Epoch: 31, Train Loss: 0.600\n","Epoch: 32, Train Loss: 0.601\n","Epoch: 33, Train Loss: 0.602\n","Epoch: 34, Train Loss: 0.601\n","Epoch: 35, Train Loss: 0.600\n","Epoch: 36, Train Loss: 0.599\n","Epoch: 37, Train Loss: 0.599\n","Epoch: 38, Train Loss: 0.599\n","Epoch: 39, Train Loss: 0.600\n","Epoch: 40, Train Loss: 0.600\n","Epoch: 41, Train Loss: 0.598\n","Epoch: 42, Train Loss: 0.598\n","Epoch: 43, Train Loss: 0.598\n","Epoch: 44, Train Loss: 0.598\n","Epoch: 45, Train Loss: 0.599\n","Epoch: 46, Train Loss: 0.598\n","Epoch: 47, Train Loss: 0.598\n","Epoch: 48, Train Loss: 0.598\n","Epoch: 49, Train Loss: 0.597\n","Epoch: 50, Train Loss: 0.597\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"J0QeHsOcuVCh","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600386661985,"user_tz":420,"elapsed":496,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"d97efc97-26d2-4d91-e074-63a89bd5b525"},"source":["# Load test file\n","id = []\n","original = []\n","\n","with open('semeval-2020-task-7-dataset/subtask-1/test.csv', 'r') as csvfile:\n","  reader = csv.DictReader(csvfile)\n","  for row in reader:\n","    id.append(row['id'])\n","\n","    edit = row['edit']\n","    original.append(re.sub('<[a-zA-z0-9]*/>', edit, row['original']))\n","\n","print(\"Result: \")\n","print(\"Test Corpus size: \" + str(len(original)))"],"execution_count":37,"outputs":[{"output_type":"stream","text":["Result: \n","Test Corpus size: 3024\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"cXR2GUieuZ5Q","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":102},"executionInfo":{"status":"ok","timestamp":1600386665083,"user_tz":420,"elapsed":961,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"cfa455a6-3c07-4825-a692-988ee248e961"},"source":["model.eval()\n","\n","tokenized_original = get_tokenized_corpus(original)\n","print(len(tokenized_original))\n","\n","sent_tensor = get_test_inputs(tokenized_original, word2idx)\n","\n","print(f'Vocabulary size: {len(word2idx)}')\n","print('Test set tensor:')\n","print(sent_tensor.size())\n","\n","\n","with torch.no_grad():\n","  pred = model(sent_tensor).squeeze().tolist()\n","\n","print(len(pred))"],"execution_count":38,"outputs":[{"output_type":"stream","text":["3024\n","Vocabulary size: 17103\n","Test set tensor:\n","torch.Size([3024, 26])\n","3024\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"37PdeBB_ucUX","colab_type":"code","colab":{},"executionInfo":{"status":"ok","timestamp":1600386667256,"user_tz":420,"elapsed":528,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}}},"source":["# Write the prediction to csv file\n","if os.path.exists('task-1-output.csv'):\n","  os.remove('task-1-output.csv')\n","\n","with open('task-1-output.csv', 'w') as outf:\n","  writer = csv.writer(outf)\n","  writer.writerow(['id', 'pred'])\n","  for i in range(len(id)):\n","    writer.writerow([id[i], pred[i]])\n"],"execution_count":39,"outputs":[]},{"cell_type":"markdown","metadata":{"id":"15-hyMivLiAz","colab_type":"text"},"source":["## Subtask 2 ##"]},{"cell_type":"code","metadata":{"id":"zGq7r-F5LkVf","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":51},"executionInfo":{"status":"ok","timestamp":1600294686530,"user_tz":420,"elapsed":456,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"4c51486c-0199-4641-b135-f4c9ea657093"},"source":["id = set()\n","corpus = []\n","grade = []\n","\n","with open('semeval-2020-task-7-dataset/subtask-2/train.csv', newline='') as csvfile:\n","  reader = csv.DictReader(csvfile)\n","  for row in reader:\n","    ids = row['id'].split('-')\n","\n","    if not ids[0] in id:\n","      edit1 = row['edit1']\n","      corpus.append(re.sub('<[a-zA-z0-9]*/>', edit1, row['original1'])) # Substitute original tag with edits\n","      grade.append(float(row['meanGrade1']))\n","      id.add(ids[0])\n","\n","    if not ids[1] in id:\n","      edit2 = row['edit2']\n","      corpus.append(re.sub('<[a-zA-z0-9]*/>', edit2, row['original2'])) # Substitute original tag with edits\n","      grade.append(float(row['meanGrade2']))\n","      id.add(ids[1])\n","\n","with open('semeval-2020-task-7-dataset/subtask-2/train_funlines.csv', newline='') as csvfile:\n","  reader = csv.DictReader(csvfile)\n","  for row in reader:\n","    ids = row['id'].split('-')\n","\n","    if not ids[0] in id:\n","      edit1 = row['edit1']\n","      corpus.append(re.sub('<[a-zA-z0-9]*/>', edit1, row['original1'])) # Substitute original tag with edits\n","      grade.append(float(row['meanGrade1']))\n","      id.add(ids[0])\n","\n","    if not ids[1] in id:\n","      edit2 = row['edit2']\n","      corpus.append(re.sub('<[a-zA-z0-9]*/>', edit2, row['original2'])) # Substitute original tag with edits\n","      grade.append(float(row['meanGrade2']))\n","      id.add(ids[1])\n","\n","print(\"Result: \")\n","print(\"Corpus size: \" + str(len(corpus)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Result: \n","Corpus size: 13049\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"lR97pAYHQlhD","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":153},"executionInfo":{"status":"ok","timestamp":1600294694672,"user_tz":420,"elapsed":5577,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"9e245ce2-cfb2-467b-f5ea-63365134ec53"},"source":["# Preprocess Corpus\n","tokenized_corpus = get_tokenized_corpus(corpus)\n","print(len(tokenized_corpus))\n","word2idx = get_word2idx(tokenized_corpus)\n","train_sent_tensor, train_label_tensor = get_model_inputs(tokenized_corpus, word2idx, grade)\n","\n","print(f'Vocabulary size: {len(word2idx)}')\n","print('Training set tensor:')\n","print(train_sent_tensor.size())\n","print(train_sent_tensor[0])\n","print('Training Label tensor:')\n","print(train_label_tensor.size())"],"execution_count":null,"outputs":[{"output_type":"stream","text":["13049\n","Vocabulary size: 13453\n","Training set tensor:\n","torch.Size([13049, 28])\n","tensor([ 1,  2,  3,  1,  4,  5,  6,  7,  8,  1,  9, 10, 11,  1,  0,  0,  0,  0,\n","         0,  0,  0,  0,  0,  0,  0,  0,  0,  0])\n","Training Label tensor:\n","torch.Size([13049])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"6ghCaf9sQv3X","colab_type":"code","colab":{}},"source":["# Hyperparameters\n","INPUT_DIM = len(word2idx)\n","EMBEDDING_DIM = 64\n","HIDDEN_DIM = 128\n","OUTPUT_DIM = 1\n","BIDIRECTIONAL = False\n","DROPOUT = 0.1\n","PAD_IDX = 0\n","EPOCHS = 50\n","\n","model = RNN(INPUT_DIM, \n","            EMBEDDING_DIM, \n","            HIDDEN_DIM, \n","            OUTPUT_DIM, \n","            BIDIRECTIONAL, \n","            DROPOUT, \n","            PAD_IDX,\n","            'lstm')"],"execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"id":"5bYJ-mW2Q2Xm","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":1000,"referenced_widgets":["32f9eb33991b41649df4200b8cae5070","ad1ac88c2b8f4f41b4c379168839f61d","92ee07c9e78d47cea915990a73c72d71","16340b3e2a764961b7b1e9d29de18ea8","6687f0b579ff4ff9b15c527795066de1","652599fcd79040c382b29f1721851607","f0bc6664e62243a8bef99229109e9245","47e77901e4554a078bfcda1a4fcec0af"]},"executionInfo":{"status":"ok","timestamp":1600295459985,"user_tz":420,"elapsed":313537,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"efefad76-be9f-44dc-b8b7-30a85458e17a"},"source":["# Print the model\n","print(model)\n","\n","# we use the Adam optimizer\n","optimizer = optim.Adam(model.parameters())\n","\n","# Use MSE for loss\n","loss_fn = nn.MSELoss()\n","\n","# Input and label tensors\n","feature = train_sent_tensor\n","target = train_label_tensor\n","\n","################\n","# Start training\n","################\n","print(f'Will train for {EPOCHS} epochs')\n","loss_hist = []\n","\n","with tqdm(range(1, EPOCHS + 1)) as pbar:\n","  for epoch in pbar:\n","    # to ensure the dropout (explained later) is \"turned on\" while training\n","    # good practice to include even if do not use here\n","    model.train()\n","    \n","    # we zero the gradients as they are not removed automatically\n","    optimizer.zero_grad()\n","    \n","    # squeeze is needed as the predictions will have the shape (batch size, 1)\n","    # and we need to remove the dimension of size 1\n","    predictions = model(feature).squeeze()\n","\n","    # Compute the loss\n","    loss = loss_fn(predictions, target)\n","    # Q. Compute here the MSE loss\n","    train_loss = loss.item()\n","\n","    # calculate the gradient of each parameter\n","    loss.backward()\n","\n","    # update the parameters using the gradients and optimizer algorithm \n","    optimizer.step()\n","    \n","    pbar.set_description(f'Epoch: {epoch:02}')\n","    print(f'Epoch: {epoch:02}, Train Loss: {train_loss:.3f}')\n","    loss_hist.append(train_loss)\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["RNN(\n","  (embedding): Embedding(13453, 64, padding_idx=0)\n","  (rnn): LSTM(64, 128, batch_first=True)\n","  (fc): Linear(in_features=128, out_features=1, bias=True)\n","  (dropout): Dropout(p=0.1, inplace=False)\n",")\n","Will train for 50 epochs\n"],"name":"stdout"},{"output_type":"display_data","data":{"application/vnd.jupyter.widget-view+json":{"model_id":"32f9eb33991b41649df4200b8cae5070","version_minor":0,"version_major":2},"text/plain":["HBox(children=(FloatProgress(value=0.0, max=50.0), HTML(value='')))"]},"metadata":{"tags":[]}},{"output_type":"stream","text":["Epoch: 01, Train Loss: 1.230\n","Epoch: 02, Train Loss: 1.188\n","Epoch: 03, Train Loss: 1.147\n","Epoch: 04, Train Loss: 1.107\n","Epoch: 05, Train Loss: 1.066\n","Epoch: 06, Train Loss: 1.024\n","Epoch: 07, Train Loss: 0.980\n","Epoch: 08, Train Loss: 0.933\n","Epoch: 09, Train Loss: 0.882\n","Epoch: 10, Train Loss: 0.826\n","Epoch: 11, Train Loss: 0.761\n","Epoch: 12, Train Loss: 0.685\n","Epoch: 13, Train Loss: 0.593\n","Epoch: 14, Train Loss: 0.482\n","Epoch: 15, Train Loss: 0.388\n","Epoch: 16, Train Loss: 0.506\n","Epoch: 17, Train Loss: 0.488\n","Epoch: 18, Train Loss: 0.405\n","Epoch: 19, Train Loss: 0.368\n","Epoch: 20, Train Loss: 0.373\n","Epoch: 21, Train Loss: 0.387\n","Epoch: 22, Train Loss: 0.399\n","Epoch: 23, Train Loss: 0.402\n","Epoch: 24, Train Loss: 0.399\n","Epoch: 25, Train Loss: 0.392\n","Epoch: 26, Train Loss: 0.381\n","Epoch: 27, Train Loss: 0.370\n","Epoch: 28, Train Loss: 0.359\n","Epoch: 29, Train Loss: 0.355\n","Epoch: 30, Train Loss: 0.355\n","Epoch: 31, Train Loss: 0.360\n","Epoch: 32, Train Loss: 0.366\n","Epoch: 33, Train Loss: 0.368\n","Epoch: 34, Train Loss: 0.367\n","Epoch: 35, Train Loss: 0.362\n","Epoch: 36, Train Loss: 0.357\n","Epoch: 37, Train Loss: 0.354\n","Epoch: 38, Train Loss: 0.353\n","Epoch: 39, Train Loss: 0.354\n","Epoch: 40, Train Loss: 0.356\n","Epoch: 41, Train Loss: 0.358\n","Epoch: 42, Train Loss: 0.358\n","Epoch: 43, Train Loss: 0.358\n","Epoch: 44, Train Loss: 0.357\n","Epoch: 45, Train Loss: 0.355\n","Epoch: 46, Train Loss: 0.354\n","Epoch: 47, Train Loss: 0.353\n","Epoch: 48, Train Loss: 0.352\n","Epoch: 49, Train Loss: 0.352\n","Epoch: 50, Train Loss: 0.354\n","\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3xMi-gy-U0Xb","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":68},"executionInfo":{"status":"ok","timestamp":1600295477991,"user_tz":420,"elapsed":1088,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"837fe171-295f-4c8f-8982-c5e19a9bfd0c"},"source":["# Load test file\n","id = []\n","original1 = []\n","original2 = []\n","\n","with open('semeval-2020-task-7-dataset/subtask-2/test.csv', 'r') as csvfile:\n","  reader = csv.DictReader(csvfile)\n","  for row in reader:\n","    id.append(row['id'])\n","\n","    edit1 = row['edit1']\n","    original1.append(re.sub('<[a-zA-z0-9]*/>', edit1, row['original1']))\n","    edit2 = row['edit2']\n","    original2.append(re.sub('<[a-zA-z0-9]*/>', edit2, row['original2']))\n","\n","print(\"Result: \")\n","print(\"Dev1 Corpus size: \" + str(len(original1)))\n","print(\"Dev2 Corpus size: \" + str(len(original2)))"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Result: \n","Dev1 Corpus size: 2960\n","Dev2 Corpus size: 2960\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"viJt1W6IVelX","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":357},"executionInfo":{"status":"ok","timestamp":1600295482569,"user_tz":420,"elapsed":1502,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"30e8aad3-815b-4739-ce90-82d80a081367"},"source":["model.eval()\n","\n","tokenized_original1 = get_tokenized_corpus(original1)\n","tokenized_original2 = get_tokenized_corpus(original2)\n","print(len(tokenized_original1))\n","print(len(tokenized_original2))\n","\n","orgn1_sent_tensor = get_test_inputs(tokenized_original1, word2idx)\n","orgn2_sent_tensor = get_test_inputs(tokenized_original2, word2idx)\n","\n","print(f'Vocabulary size: {len(word2idx)}')\n","print('Dev set tensor:')\n","print(orgn1_sent_tensor.size())\n","print(orgn2_sent_tensor.size())\n","\n","\n","with torch.no_grad():\n","  pred_org1 = model(orgn1_sent_tensor).squeeze(1)\n","  pred_org2 = model(orgn2_sent_tensor).squeeze(1)\n","\n","print(pred_org1[0:5])\n","print(pred_org2[0:5])"],"execution_count":null,"outputs":[{"output_type":"stream","text":["2960\n","2960\n","Vocabulary size: 13453\n","Dev set tensor:\n","torch.Size([2960, 25])\n","torch.Size([2960, 25])\n","tensor([[[1.0458],\n","         [1.0458],\n","         [1.0484],\n","         ...,\n","         [0.9114],\n","         [0.9114],\n","         [0.8937]]])\n","tensor([[[1.0484],\n","         [1.0482],\n","         [1.0482],\n","         ...,\n","         [0.8937],\n","         [0.8894],\n","         [0.8894]]])\n"],"name":"stdout"}]},{"cell_type":"code","metadata":{"id":"3qiloBSIVjC0","colab_type":"code","colab":{"base_uri":"https://localhost:8080/","height":85},"executionInfo":{"status":"ok","timestamp":1600295495954,"user_tz":420,"elapsed":577,"user":{"displayName":"Chen Meng","photoUrl":"","userId":"04991742756761854047"}},"outputId":"de537128-6b1f-4016-dfef-3b701ac6d2e8"},"source":["# Write the prediction to csv file\n","pred = []\n","for i in range(len(pred_org1[0])):\n","  pred.append(0 if pred_org1[0][i][0].item() == pred_org2[0][i][0].item() else (1 if pred_org1[0][i][0].item() > pred_org2[0][i][0].item() else 2))\n","\n","!unzip semeval-2020-task-7-dataset/subtask-2/baseline.zip\n","  \n","with open('task-2-output.csv', 'w') as outf:\n","  writer = csv.writer(outf)\n","  writer.writerow(['id', 'pred'])\n","  for i in range(len(id)):\n","    writer.writerow([id[i], pred[i]])\n"],"execution_count":null,"outputs":[{"output_type":"stream","text":["Archive:  semeval-2020-task-7-dataset/subtask-2/baseline.zip\n","  inflating: task-2-output.csv       \n","   creating: __MACOSX/\n","  inflating: __MACOSX/._task-2-output.csv  \n"],"name":"stdout"}]}]}